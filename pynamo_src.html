<html>
<head>
<title>Exploring the Dynamo Paper in Python</title>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="author" content="David Drysdale">
<meta name="keywords" content="drysdale, Dynamo, Python">
<link rel="stylesheet" href="pygments.css" />
</head>
<body>
<h1>Exploring the Dynamo Paper in Python</h1>
<p>
Like many other people, I found the 
<a href="http://s3.amazonaws.com/AllThingsDistributed/sosp/amazon-dynamo-sosp2007.pdf">paper [PDF]</a> 
that describes Amazon's Dynamo system intensely interesting.
</p>
<p>
To fully understand something software-related, I always find it's best to actually write some code.
So I sat down to write an implementation of the key ideas from the Dynamo paper, in Python, and this
page holds the results.
</p>
<p>
In line with this original intent, I should point out that the code here is 
<b>pedagogical</b> rather than practical.  For example,  I deliberately use inefficent 
implementations in places &ndash; I'd rather have a slow implementation that just uses the Python standard
library, than a fast version with distractions (by either requiring additional <code>import</code>s, or
by including implementations of data structure that aren't specific to Dynamo).
</p>
<p>
I've also built the system on top of a simulated network, rather than on top of a real network or web server.
This means I can more easily test different scenarios and track what's going on (more on the framework
<a href="#framework">at the end</a>).
</p>
<p>
For my final proviso, I should point out that I'm not going to explain much of the original ideas in the
Dynamo paper.  It's a perfectly clear and readable paper, so there's no gain in re-explaining it, except for
the rare cases where some important details have been swept under the carper.
</p>

<a name="consistent_hash"><h2>Section 4.2/4.3: Partitioning Algorithm</h2></a>
<p>
The first area to explore is the consistent hashing algorithm described in section 4.2 of the paper.
The constructor for the <code>ConsistentHashTable</code> builds up the list of nodes, and the 
<code>find_nodes</code> method returns the <i>preference list</i> of nodes for the key (where the first
entry in the list is the <i>coordinator</i>). 
</p>
<p>
The first implementation just implements the straightforward one-hash-per-node approach:
</p>
#include <hash_simple.py>
<p>
The paper indicates a couple of problems with this simplistic approach, which we can check by feeding in some
random data:
<ul>
  <li><b>The distribution of hash values can be 'lumpy'</b>: 
   #result <python hash_simple.py -s 1 HashSimpleTestCase.testDistribution>
  </li>
  <li><b>All of the traffic of a failed node moves to a single other node</b>:
    Adding a node to the <code>avoid</code> parameter means that the (single) next node round the 
    hash ring gets all of the keys that would have gone to the failed node.
  </li>
</ul>
</p>
<p>
So we move to the second implementation, where each node gets multiple points in the hash ring, known
as <i>virtual nodes</i>.  We implement this very simply, by adding a ":<i>&lt;count&gt;</i>" suffix to the
string that we hash for the node position.
</p>
#include <hash_multiple.py>
<p>
Let's see how much different this makes by feeding in some random data to a set of 50 nodes with 10 copies of
each node in the hash ring.
<ul>
  <li><b>Distribution of hash values</b>: 
   #result <python hash_multiple.py -s 1 HashMultipleTestCase.testDistribution>
  </li>
  <li><b>Distribution of traffic from a failed node</b>:
    #result <python hash_multiple.py -s 1 HashMultipleTestCase.testFailover>
  </li>
</ul>
For 50 nodes with <b>100</b> copies of each node in the hash ring.
<ul>
  <li><b>Distribution of hash values</b>: 
   #result <python hash_multiple.py -s 1 -r 100 HashMultipleTestCase.testDistribution>
  </li>
  <li><b>Distribution of traffic from a failed node</b>:
    #result <python hash_multiple.py -s 1 -r 100 HashMultipleTestCase.testFailover>
  </li>
</ul>


<a name="consistent_hash"><h2>Section 4.4: Vector Clocks</h2></a>
<p>
A vector clock is easy to implement; it's basically a dictionary whose keys are nodes
and whose values are the last-seen sequence number for that node.
</p>
#include <vectorclock.py:1>
<p>
We can add entries to the vector clock, simulating different nodes and their counters, with one proviso: a
node's counter isn't allowed to go backwards.
</p>
#python
from vectorclock import VectorClock
v = VectorClock()
print v
v.update('A', 1)
print v
v.update('A', 3)
print v
v.update('B', 1001)
print v
v.update('B', 1002)
print v
v.update('B', 1)
#endpython
<p>
We can also define an ordering operation <b>&lt;</b> on vector clocks
(together with all the other comparison operations) by adding the relevant rich comparison methods 
to the <code>VectorClock</code> class.
</p>
#include <vectorclock.py:2>
<p>
This is a <a href="http://en.wikipedia.org/wiki/Partially_ordered_set">partial order</a>:
<ul>
  <li>it's reflexive: <code>a &lt;= a</code> always holds (because <code>a==a</code>)</li>
  <li>it's antisymmetric: if <code>a &lt; b</code> and <code>b &lt; a</code>, then <code>a==b</code></li>
  <li>it's transitive: if <code>a &lt; b</code> and <code>b &lt; c</code>, then <code>a &lt;= c</code></li>
</ul>
but it's not a total order &ndash; it's possible for neither <code>a &lt; b</code>
nor <code>b &lt; a</code> to hold.
</p>
#python
from vectorclock import VectorClock
v1 = VectorClock().update('A', 1).update('B', 2)
v2 = VectorClock().update('A', 2).update('B', 3)
print (v1 < v2)
v3 = VectorClock().update('X', 1).update('Y', 2)
print (v1 < v3)
print (v3 < v1)
#endpython
<p>
This partial order forms the basis for the more important thing we can do with vector clocks &ndash; combine
them.  
</p>
#include <vectorclock.py:3>
<p>
This operation folds together those vector clocks that are direct ancestors of each other, but keeping separate those
that are not.
</p>
#python
diverged_clocks = VectorClock.coalesce((v1, v2, v3))
for vc in diverged_clocks: print vc
print (diverged_clocks[0] < diverged_clocks[1])
print (diverged_clocks[1] < diverged_clocks[0])
#endpython
<p>
Finally, we need to be able to build a single vector clock that has an arbitrary set of direct ancestors; in
other words, a way of reconverging a divergent set of vector clocks.
</p>
#include <vectorclock.py:4>
<p>
Code that uses Dynamo needs to be able to resolve inconsistencies itself.  When it has done so, the new value
for the key needs a vector clock that makes it clear that the inconsistency has been resolved.
</p>
#python
converged_clock = VectorClock.converge(diverged_clocks)
print converged_clock
print (v1 < converged_clock)
print (v2 < converged_clock)
print (v3 < converged_clock)
#endpython
<p>
The Dynamo paper also discusses the problem that the size of vector clocks can become large as more and more
nodes get involved in the history of changes to a particular key/value.  To get around this, they suggest
keeping a timestamp along with the sequence number, and throwing away the oldest entry in a vector clock when
it has more than 10 entries.  This is easily implemented as a subclass of <code>VectorClock</code>, but we
won't bother using this variant from here on.
</p>
#include <vectorclockt.py>


<a name="framework"><h2>Appendix: Node Simulation Framework</h2></a>

<ul>
  <li>framework.py: </li>
  <li>history.py: </li>
  <li>timer.py: </li>
  <li>testutils.py: </li>
  <li>logconfig.py: </li>
  <li>message.py: </li>
</ul>
<a name=""><h2>Epilog</h2></a>
<p>
A full copy of this project (text, source, scripts) can be 
<a href="pynamo.tgz">downloaded here</a>.  The text is available under
the <a href="http://www.gnu.org/licenses/fdl.html">GFDL 1.3</a>, the code is available under
<a href="http://www.gnu.org/licenses/old-licenses/gpl-2.0.html">version 2 of the GPL</a>.
<hr>
<p>Copyright (c) 2010-2011, David Drysdale</p>

<p>Permission is granted to copy, distribute and/or modify this document
under the terms of the GNU Free Documentation License, Version 1.3 or any
later version published by the Free Software Foundation; with no Invariant
Sections, with no Front-Cover Texts, and with no Back-Cover Texts.  A copy
of the license is available 
<a href="http://www.gnu.org/copyleft/fdl.html">here</a>.</p>
<hr>
<p><a href="http://www.lurklurk.org/">Back to Home Page</a></p>
<hr>
<p><a href="mailto:dmd at_sign_here lurklurk dot_here org">Contact me</a></p>
<script src="http://www.google-analytics.com/urchin.js" type="text/javascript">
</script>
<script type="text/javascript">
_uacct = "UA-707535-2";
urchinTracker();
</script>
</body>
</html>

